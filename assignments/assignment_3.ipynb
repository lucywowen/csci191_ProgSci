{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea692bda",
   "metadata": {},
   "source": [
    "# Super‑Basic ML with scikit‑learn\n",
    "\n",
    "**Sections**\n",
    "1) Linear regression (predict a numeric target)  \n",
    "2) Logistic regression (predict a simple binary label)  \n",
    "3) Mini 'Kaggle' style analysis on one of the provided datasets (train on train, evaluate generalization on separate test dataset)\n",
    "\n",
    "The goal is to keep everything **simple and readable**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed54be09",
   "metadata": {},
   "source": [
    "## 0) Setup & Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe59d4",
   "metadata": {},
   "source": [
    "We'll use **Palmer Penguins** again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546362c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write load_penguins() function \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "penguins = load_penguins()\n",
    "penguins.columns = [c.strip().lower().replace(' ','_') for c in penguins.columns]\n",
    "penguins.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0070586",
   "metadata": {},
   "source": [
    "## 1) Linear Regression (super basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e608e7",
   "metadata": {},
   "source": [
    "**Task.** Predict `body_mass_g` from **one feature**: `flipper_length_mm`.\n",
    "\n",
    "We'll do a simple train/test split and compute **R²** and **RMSE**. We'll also draw a quick **true vs predicted** scatter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0197c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build X (flipper_length_mm) and y (body_mass_g), drop missing rows\n",
    "# TODO: Split into train/test (test_size=0.25, random_state=42)\n",
    "# TODO: Create a scikit-learn Pipeline: StandardScaler -> LinearRegression\n",
    "# TODO: Fit on train, predict on test, compute R^2 and RMSE, then plot y_true vs y_pred\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 1) Build X, y\n",
    "# YOUR CODE HERE\n",
    "# X = ...\n",
    "# y = ...\n",
    "\n",
    "# 2) Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# 3) Pipeline\n",
    "# pipe = Pipeline([('scaler', StandardScaler()), ('linreg', LinearRegression())])\n",
    "\n",
    "# 4) Fit & predict\n",
    "# pipe.fit(X_train, y_train)\n",
    "# y_pred = pipe.predict(X_test)\n",
    "\n",
    "# 5) Metrics\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "# rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "# print(f\"R^2: {r2:.3f}, RMSE: {rmse:.1f} g\")\n",
    "\n",
    "# 6) Plot: true vs predicted\n",
    "# plt.figure(figsize=(5,4))\n",
    "# plt.scatter(y_test, y_pred, alpha=0.7)\n",
    "# plt.xlabel(\"True body_mass_g\"); plt.ylabel(\"Predicted body_mass_g\")\n",
    "# min_v = min(y_test.min(), y_pred.min()); max_v = max(y_test.max(), y_pred.max())\n",
    "# plt.plot([min_v, max_v], [min_v, max_v], linestyle='--')\n",
    "# plt.title(\"Linear regression: true vs predicted\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0ff24",
   "metadata": {},
   "source": [
    "## 2) Logistic Regression (super basic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9b358",
   "metadata": {},
   "source": [
    "**Task.** Classify **Adelie vs. not‑Adelie** using only **two features**: `bill_length_mm` and `bill_depth_mm`.\n",
    "\n",
    "We'll compute a simple **accuracy** and display a tiny **confusion matrix**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ab4565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make a binary label y_bin = 1 if species == 'Adelie' else 0\n",
    "# TODO: Build X with [bill_length_mm, bill_depth_mm], drop rows with NaNs in X or y\n",
    "# TODO: Train/test split (test_size=0.25, random_state=42)\n",
    "# TODO: Pipeline: StandardScaler -> LogisticRegression\n",
    "# TODO: Fit, predict, print accuracy, and plot a small confusion matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# 1) Build X, y_bin\n",
    "# YOUR CODE HERE\n",
    "# X = ...\n",
    "# y_bin = ...\n",
    "\n",
    "# 2) Split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# 3) Pipeline\n",
    "# clf = Pipeline([('scaler', StandardScaler()), ('logreg', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "# 4) Fit & predict\n",
    "# clf.fit(X_train, y_train)\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# 5) Accuracy\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Accuracy: {acc:.3f}\")\n",
    "\n",
    "# 6) Confusion matrix plot\n",
    "# cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "# import numpy as np\n",
    "# fig, ax = plt.subplots(figsize=(4,4))\n",
    "# im = ax.imshow(cm, interpolation='nearest')\n",
    "# ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "# ax.set_xticklabels(['not Adelie','Adelie']); ax.set_yticklabels(['not Adelie','Adelie'])\n",
    "# for i in range(cm.shape[0]):\n",
    "#     for j in range(cm.shape[1]):\n",
    "#         ax.text(j, i, str(cm[i,j]), ha='center', va='center')\n",
    "# ax.set_xlabel('Predicted'); ax.set_ylabel('True'); ax.set_title('Confusion matrix')\n",
    "# fig.colorbar(im, ax=ax, shrink=0.8); fig.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b32bc23",
   "metadata": {},
   "source": [
    "## 3) Mini 'Kaggle' style analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4808acb3",
   "metadata": {},
   "source": [
    "Pick **one** of the **provided datasets** found in 'https://github.com/XenoQueer/Class_repo-liam/tree/main/data/prog_sci_data'. Each has a **train** file that ends with '_dataset' and a new separate **test** file.\n",
    "\n",
    "- The test file **has labels**, so we will evaluate accuracy/RMSE on it.  \n",
    "\n",
    "We'll keep the modeling **super basic** and numeric‑only:\n",
    "- numeric imputer (mean) + standardize;\n",
    "- **LinearRegression** if your task is **regression**,\n",
    "- **LogisticRegression** if your task is **classification**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed7dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# === Load ===\n",
    "# 0) Load the data\n",
    "# YOUR CODE HERE\n",
    "# make sure you load in both the training and the testing data\n",
    "\n",
    "# === Clean data ===\n",
    "# 1) Make sure your data is cleaned \n",
    "# YOUR CODE HERE \n",
    "# perform some basic visualization to make sure everything is ready to do for your analysis\n",
    "# you can re-use your past work from previous analyses if you'd like!\n",
    "\n",
    "# === Build X and y ===\n",
    "# 2) Parse your data into X_train, y_train, X_gen, y_gen\n",
    "# YOUR CODE HERE\n",
    "# you'll want to run and refine your analysis for just the training data and then at the end test on the generalization data\n",
    "\n",
    "# === Data split ===\n",
    "# 3) Split only your training data\n",
    "# YOUR CODE HERE\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)\n",
    "\n",
    "# === Pipeline ===\n",
    "# 4) Create your pipeline\n",
    "# YOUR CODE HERE\n",
    "# for example:\n",
    "# pipe = Pipeline([('scaler', StandardScaler()), ('logreg', LogisticRegression(max_iter=1000))])\n",
    "# pipe = Pipeline([('scaler', StandardScaler()), ('linreg', LinearRegression())])\n",
    "\n",
    "# === Fit & predict ===\n",
    "# 5) Fit your model to the training data and test on the testing data (not the generalization data yet)\n",
    "# YOUR CODE HERE\n",
    "# pipe.fit(X_train, y_train)\n",
    "# y_pred = pipe.predict(X_test)\n",
    "\n",
    "# === Metrics ===\n",
    "# 6) Use appropriate metrics for your analysis (regression vs classification) to assess your model\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# === Refine model ===\n",
    "# 7) Repeat steps 4-6 with different parameters/pipeline changes until satisfied with test results\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# === Evaluate model ===\n",
    "# 8) Assess the generalization of your model using X_gen and y_gen\n",
    "# YOUR CODE HERE\n",
    "# Don't forget to visualize your results in the appropriate manner! (Scatter or confusion matrix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60293f92",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ What to submit\n",
    "- **Section 1**: your pipeline code and the R²/RMSE printout (+ the scatter).\n",
    "- **Section 2**: your pipeline code and the accuracy printout (+ the confusion matrix).\n",
    "- **Section 3**: your train/test evaluation printout and metric printout (scatter or confusion matrix)\n",
    "\n",
    "## Scoring (100 pts)\n",
    "- *Linear regression* — 35 pts\n",
    "- *Logistic regression* — 35 pts\n",
    "- *Mini Kaggle analysis* — 30 pts\n",
    "\n",
    "> Bonus (+5): Provide one or two sentences on what worked and why for your Kaggle analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
